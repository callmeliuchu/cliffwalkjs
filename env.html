<!DOCTYPE html>
<html>
<head>
    <title>CliffWalk 2x3</title>
    <style>
        .grid {
            display: grid;
            gap: 2px;
            margin: 20px;
            border: 2px solid #333;
            padding: 2px;
            background-color: #f0f0f0;
            width: fit-content;
        }
        .cell {
            width: 60px;
            height: 60px;
            border: 1px solid #000;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 14px;
            background-color: white;
            position: relative;
            transition: all 0.2s ease;
        }
        .cell::after {
            content: attr(title);
            position: absolute;
            font-size: 10px;
            top: 2px;
            left: 2px;
            color: #666;
        }
        .agent {
            color: white !important;
            font-weight: bold;
            transform: scale(1.05);
            /* 使用叠加的背景色 */
            background-color: rgba(76, 175, 80, 0.7) !important;
        }
        .cliff {
            background-color: #f44336;
            color: white;
            font-weight: bold;
        }
        .goal {
            background-color: #2196F3;
            color: white;
            font-weight: bold;
        }
        .info {
            margin: 20px;
            font-family: monospace;
        }
        .controls {
            margin: 20px;
        }
        .controls button {
            margin-right: 10px;
            padding: 5px 10px;
            cursor: pointer;
        }
    </style>
</head>
<body>
    <div class="grid" id="grid"></div>
    <div class="info">
        <p>Current State: <span id="state">0</span></p>
        <p>Last Action: <span id="action">None</span></p>
        <p>Last Reward: <span id="reward">0</span></p>
        <p>Episode Steps: <span id="steps">0</span></p>
        <p>Total Reward: <span id="total-reward">0</span></p>
        <button onclick="resetEnv()">Reset Environment</button>
    </div>

    <script>
        class CliffWalkEnv {
            constructor(rows=2, cols=3) {
                this.rows = rows;
                this.cols = cols;
                this.reset();
            }

            reset() {
                // Start at bottom-left corner
                this.state = this.cols * (this.rows - 1);
                this.done = false;
                this.steps = 0;
                this.totalReward = 0;
                return this.state;
            }

            step(action) {
                if (this.done) {
                    console.log("Episode already done!");
                    return [this.state, 0, true];
                }

                this.steps += 1;
                let row = Math.floor(this.state / this.cols);
                let col = this.state % this.cols;
                let reward = -1;
                let done = false;

                // Move according to action
                switch(action) {
                    case 0: // up
                        if (row > 0) row -= 1;
                        break;
                    case 1: // right
                        if (col < this.cols - 1) col += 1;
                        break;
                    case 2: // down
                        if (row < this.rows - 1) row += 1;
                        break;
                    case 3: // left
                        if (col > 0) col -= 1;
                        break;
                }

                // Calculate new state
                this.state = row * this.cols + col;

                // Check if hit cliff or reached goal
                if (row === this.rows - 1 && col > 0 && col < this.cols - 1) {
                    reward = -100;  // Cliff
                    // done = true;
                } else if (row === this.rows - 1 && col === this.cols - 1) {
                    reward = 0;     // Goal
                    done = true;
                }

                this.done = done;
                this.totalReward += reward;

                return [this.state, reward, done];
            }
        }

        const env = new CliffWalkEnv(4, 8);
        let currentState = env.reset();

        function updateGrid() {
            const grid = document.getElementById('grid');
            grid.style.gridTemplateColumns = `repeat(${env.cols}, 60px)`;
            grid.innerHTML = '';
            
            for (let i = 0; i < env.rows; i++) {
                for (let j = 0; j < env.cols; j++) {
                    const cell = document.createElement('div');
                    cell.className = 'cell';
                    const stateNum = i * env.cols + j;
                    
                    cell.title = `${stateNum}`;
                    
                    if (stateNum === currentState) {
                        cell.classList.add('agent');
                        cell.textContent = '👾';
                    } else if (i === env.rows - 1 && j > 0 && j < env.cols - 1) {
                        cell.classList.add('cliff');
                        cell.textContent = '💀';
                    } else if (i === env.rows - 1 && j === env.cols - 1) {
                        cell.classList.add('goal');
                        cell.textContent = '🎯';
                    } else {
                        cell.textContent = stateNum;
                    }
                    
                    grid.appendChild(cell);
                }
            }
        }

        function updateInfo(action, reward) {
            document.getElementById('state').textContent = currentState;
            document.getElementById('action').textContent = 
                action !== undefined ? ['Up', 'Right', 'Down', 'Left'][action] : 'None';
            document.getElementById('reward').textContent = reward !== undefined ? reward : 0;
            document.getElementById('steps').textContent = env.steps;
            document.getElementById('total-reward').textContent = env.totalReward;
        }

        async function resetEnv() {
            currentState = env.reset();
            updateGrid(); // 使用updateGrid来完全重置网格
            updateInfo();
        }

        // 修改addControls函数
        function addControls() {
            // 先检查是否已经存在controls
            let controls = document.querySelector('.controls');
            if (controls) {
                controls.remove();
            }

            controls = document.createElement('div');
            controls.className = 'controls';
            controls.innerHTML = `
                <button id="aiStep">AI Step</button>
                <button id="autoPlay">Auto Play</button>
                <button id="stopAutoPlay">Stop Auto Play</button>
            `;
            
            // 将controls添加到info div中
            const infoDiv = document.querySelector('.info');
            infoDiv.appendChild(controls);

            let isPlaying = false;

            async function autoPlayStep() {
                if (!isPlaying || env.done) return;
                
                console.log('Auto playing step...');  // 调试日志
                const action = agent.selectAction(currentState);
                console.log('Selected action:', action);  // 调试日志
                simulateKeyPress(action);
                await sleep(300);  // 增加延迟时间
                
                if (isPlaying) {
                    requestAnimationFrame(autoPlayStep);  // 使用requestAnimationFrame代替直接递归
                }
            }

            // 确保按钮存在后再添加事件监听器
            const aiStepBtn = document.getElementById('aiStep');
            const autoPlayBtn = document.getElementById('autoPlay');
            const stopAutoPlayBtn = document.getElementById('stopAutoPlay');

            if (aiStepBtn) {
                aiStepBtn.addEventListener('click', async () => {
                    console.log('AI Step clicked');  // 调试日志
                    if (!env.done) {
                        const action = agent.selectAction(currentState);
                        console.log('Selected action:', action);  // 调试日志
                        simulateKeyPress(action);
                    }
                });
            }

            if (autoPlayBtn) {
                autoPlayBtn.addEventListener('click', () => {
                    console.log('Auto Play clicked');  // 调试日志
                    if (!isPlaying) {
                        isPlaying = true;
                        autoPlayStep();
                    }
                });
            }

            if (stopAutoPlayBtn) {
                stopAutoPlayBtn.addEventListener('click', () => {
                    console.log('Stop Auto Play clicked');  // 调试日志
                    isPlaying = false;
                });
            }
        }

        // 修改simulateKeyPress函数，添加调试日志
        function simulateKeyPress(action) {
            const keyMap = {
                0: 'ArrowUp',
                1: 'ArrowRight',
                2: 'ArrowDown',
                3: 'ArrowLeft'
            };
            
            // 确保action是有效的数字
            if (action === undefined || action === null) {
                console.error('Invalid action:', action);
                action = Math.floor(Math.random() * 4);  // 随机选择一个动作作为后备
            }
            
            const key = keyMap[action];
            console.log('Simulating key press:', key, 'for action:', action);
            
            if (key) {
                const event = new KeyboardEvent('keydown', {
                    key: key,
                    bubbles: true,
                    cancelable: true
                });
                document.dispatchEvent(event);
            } else {
                console.error('Invalid action number:', action);
            }
        }

        // 修改键盘事件监听器
        document.addEventListener('keydown', async (event) => {
            if (env.done) return;

            let action;
            switch(event.key) {
                case 'ArrowUp':
                    action = 0;
                    break;
                case 'ArrowRight':
                    action = 1;
                    break;
                case 'ArrowDown':
                    action = 2;
                    break;
                case 'ArrowLeft':
                    action = 3;
                    break;
                default:
                    return;
            }

            const [newState, reward, done] = env.step(action);
            
            // 获取当前和新的单元格
            const oldCell = document.querySelector(`.cell[title="${currentState}"]`);
            const newCell = document.querySelector(`.cell[title="${newState}"]`);
            
            if (oldCell && newCell) {
                // 移除旧位置的agent
                oldCell.classList.remove('agent');
                if (!oldCell.classList.contains('cliff') && !oldCell.classList.contains('goal')) {
                    oldCell.style.backgroundColor = 'white';
                    oldCell.textContent = currentState;
                } else if (oldCell.classList.contains('cliff')) {
                    oldCell.textContent = '💀';
                } else if (oldCell.classList.contains('goal')) {
                    oldCell.textContent = '🎯';
                }
                
                // 添加新位置的agent
                newCell.classList.add('agent');
                newCell.textContent = '👾';
            }
            
            currentState = newState;
            updateInfo(action, reward);

            if (done) {
                console.log("Episode finished!");
                console.log("Total Steps:", env.steps);
                console.log("Total Reward:", env.totalReward);
                
                // 更新策略
                agent.update(reward);
                
                await sleep(500);
                resetEnv();
            } else {
                // 记录非终止状态的奖励
                agent.trajectory.rewards.push(reward);
            }
        });

        class SimpleNN {
            constructor(inputSize, hiddenSize, outputSize) {
                console.log('Creating NN with sizes:', inputSize, hiddenSize, outputSize);
                this.inputSize = inputSize;
                this.outputSize = outputSize;
                this.hiddenSize = hiddenSize;
                
                // 使用较小的初始权重值
                const initScale = 0.01;
                this.w1 = Array(inputSize).fill().map(() => 
                    Array(hiddenSize).fill().map(() => (Math.random() * 2 - 1) * initScale)
                );
                this.w2 = Array(hiddenSize).fill().map(() => 
                    Array(outputSize).fill().map(() => (Math.random() * 2 - 1) * initScale)
                );

                // 添加偏置项
                this.b1 = Array(hiddenSize).fill().map(() => 0);
                this.b2 = Array(outputSize).fill().map(() => 0);

                // 添加学习率
                this.learningRate = 0.01;
                
                // 添加轨迹存储
                this.clearTrajectory();
            }

            // 添加轨迹存储和清理函数
            clearTrajectory() {
                this.trajectory = {
                    states: [],
                    actions: [],
                    rewards: [],
                    logProbs: []
                };
            }

            // 记录一步轨迹
            recordStep(state, action, reward, logProb) {
                this.trajectory.states.push(state);
                this.trajectory.actions.push(action);
                this.trajectory.rewards.push(reward);
                this.trajectory.logProbs.push(logProb);
            }

            // 计算折扣回报
            computeDiscountedReturns(rewards, gamma = 0.99) {
                const returns = new Array(rewards.length).fill(0);
                let runningReturn = 0;
                
                for (let t = rewards.length - 1; t >= 0; t--) {
                    runningReturn = rewards[t] + gamma * runningReturn;
                    returns[t] = runningReturn;
                }
                
                // 标准化回报
                const mean = returns.reduce((a, b) => a + b, 0) / returns.length;
                const std = Math.sqrt(returns.reduce((a, b) => a + (b - mean) ** 2, 0) / returns.length + 1e-8);
                return returns.map(r => (r - mean) / std);
            }

            // ReLU激活函数
            relu(x) {
                return Math.max(0, x);
            }

            // 数值稳定的Softmax函数
            softmax(x) {
                try {
                    const maxVal = Math.max(...x);
                    const expValues = x.map(val => Math.exp(Math.min(val - maxVal, 20))); // 防止exp溢出
                    const sumExp = expValues.reduce((a, b) => a + b, 0);
                    if (sumExp === 0) {
                        // 如果所有值都很小，返回均匀分布
                        return Array(x.length).fill(1/x.length);
                    }
                    return expValues.map(val => val / sumExp);
                } catch (error) {
                    console.error('Softmax error:', error);
                    // 返回均匀分布作为后备方案
                    return Array(x.length).fill(1/x.length);
                }
            }

            // 前向传播
            forward(state) {
                try {
                    // 确保状态在有效范围内
                    state = Math.min(Math.max(0, state), this.inputSize - 1);

                    // 将状态转换为one-hot编码
                    const input = Array(this.inputSize).fill(0);
                    input[state] = 1;

                    // 隐藏层
                    const hidden = Array(this.hiddenSize).fill(0);
                    for (let i = 0; i < this.hiddenSize; i++) {
                        let sum = this.b1[i];
                        for (let j = 0; j < this.inputSize; j++) {
                            sum += input[j] * this.w1[j][i];
                        }
                        hidden[i] = this.relu(sum);
                    }

                    // 输出层
                    const output = Array(this.outputSize).fill(0);
                    for (let i = 0; i < this.outputSize; i++) {
                        let sum = this.b2[i];
                        for (let j = 0; j < this.hiddenSize; j++) {
                            sum += hidden[j] * this.w2[j][i];
                        }
                        output[i] = sum;
                    }

                    // 应用softmax得到动作概率
                    return this.softmax(output);
                } catch (error) {
                    console.error('Forward pass error:', error);
                    // 返回均匀分布作为后备方案
                    return Array(this.outputSize).fill(1/this.outputSize);
                }
            }

            // 修改selectAction函数
            selectAction(state) {
                try {
                    const actionProbs = this.forward(state);
                    console.log('Action probabilities:', actionProbs);
                    
                    // ε-贪婪策略
                    if (Math.random() < 0.1) {  // 10%的均匀随机探索
                        const action = Math.floor(Math.random() * this.outputSize);
                        const logProb = Math.log(actionProbs[action] + 1e-8);
                        this.recordStep(state, action, null, logProb);
                        return action;
                    }
                    
                    // 根据概率分布采样动作
                    const rand = Math.random();
                    let cumSum = 0;
                    let selectedAction = this.outputSize - 1;  // 默认值

                    for (let action = 0; action < actionProbs.length; action++) {
                        cumSum += actionProbs[action];
                        if (rand < cumSum) {
                            selectedAction = action;
                            break;
                        }
                    }

                    const logProb = Math.log(actionProbs[selectedAction] + 1e-8);
                    this.recordStep(state, selectedAction, null, logProb);
                    return selectedAction;

                } catch (error) {
                    console.error('Select action error:', error);
                    const action = Math.floor(Math.random() * this.outputSize);
                    this.recordStep(state, action, null, Math.log(0.25)); // 均匀概率
                    return action;
                }
            }

            // 策略梯度更新
            update(finalReward) {
                // 更新最后一步的奖励
                this.trajectory.rewards[this.trajectory.rewards.length - 1] = finalReward;
                
                // 计算折扣回报
                const returns = this.computeDiscountedReturns(this.trajectory.rewards);
                
                // 计算策略梯度
                for (let t = 0; t < this.trajectory.states.length; t++) {
                    const state = this.trajectory.states[t];
                    const action = this.trajectory.actions[t];
                    const G = returns[t];
                    const logProb = this.trajectory.logProbs[t];
                    
                    // 计算梯度并更新权重
                    this.backprop(state, action, G, logProb);
                }
                
                // 清理轨迹
                this.clearTrajectory();
            }

            // 反向传播更新权重
            backprop(state, action, G, logProb) {
                // 前向传播获取所有中间值
                const input = Array(this.inputSize).fill(0);
                input[state] = 1;

                // 隐藏层前向传播
                const hidden = Array(this.hiddenSize).fill(0);
                const hiddenRaw = Array(this.hiddenSize).fill(0);
                for (let i = 0; i < this.hiddenSize; i++) {
                    hiddenRaw[i] = this.b1[i];
                    for (let j = 0; j < this.inputSize; j++) {
                        hiddenRaw[i] += input[j] * this.w1[j][i];
                    }
                    hidden[i] = this.relu(hiddenRaw[i]);
                }

                // 输出层前向传播
                const output = Array(this.outputSize).fill(0);
                for (let i = 0; i < this.outputSize; i++) {
                    output[i] = this.b2[i];
                    for (let j = 0; j < this.hiddenSize; j++) {
                        output[i] += hidden[j] * this.w2[j][i];
                    }
                }

                // 计算梯度
                const grad = G * Math.exp(logProb);
                
                // 更新输出层权重
                for (let i = 0; i < this.outputSize; i++) {
                    this.b2[i] += this.learningRate * grad * (i === action ? 1 : 0);
                    for (let j = 0; j < this.hiddenSize; j++) {
                        this.w2[j][i] += this.learningRate * grad * hidden[j] * (i === action ? 1 : 0);
                    }
                }

                // 更新隐藏层权重
                for (let i = 0; i < this.hiddenSize; i++) {
                    this.b1[i] += this.learningRate * grad * (hiddenRaw[i] > 0 ? 1 : 0);
                    for (let j = 0; j < this.inputSize; j++) {
                        this.w1[j][i] += this.learningRate * grad * input[j] * (hiddenRaw[i] > 0 ? 1 : 0);
                    }
                }
            }
        }

        // 修改神经网络实例的创建
        const agent = new SimpleNN(env.rows * env.cols, 32, 4);

        // 添加一个动画延迟函数
        function sleep(ms) {
            return new Promise(resolve => setTimeout(resolve, ms));
        }

        // 确保在页面加载完成后初始化
        window.addEventListener('load', () => {
            updateGrid();
            updateInfo();
            addControls();
        });
    </script>
</body>
</html>